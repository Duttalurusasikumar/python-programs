#importing the libraries  
frompyspark.ml.evaluation import RegressionEvaluator  
frompyspark.ml.recommendation import ALS  
frompyspark.sql import Row  
no_of_lines = spark.read.text(r"C:\Users\DEVANSH SHARMA\MovieLens.csv").rdd  
no_of_parts = no_of_lines.map(lambda row: row.value.split("::"))  
ratingsRDD = no_of_lines.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),  
                                     rating=float(p[2]), timestamp=long(p[3])))  
ratings = spark.createDataFrame(ratingsRDD)  
(training, test) = ratings.randomSplit([0.8, 0.2])  
  
# Develop the recommendation model using ALS on the training data  
# Note we set cold start strategy to make sure that we don't get NaN evaluation metrics.  
als = ALS(maxIter=5, regParam=0.01, userCol="userId", itemCol="movieId", ratingCol="rating",  
    coldStartStrategy="drop")  
model = als.fit(training)  
  
# Calculate the model by computing the RMSE on the test data  
predictions = model.transform(test)  
evaluator = RegressionEvaluator(metricName="rmse", labelCol="rating",  
predictionCol="prediction")  
rmse = evaluator.evaluate(predictions)  
print("Root-mean-square error = " + str(rmse))  
  
# Evaluate top 10 movie recommendations for each user  
userRecs = model.recommendForAllUsers(10)  
# Evaluate top 10 user recommendations for each movie  
movieRecs = model.recommendForAllItems(10)  
# Evaluate top 10 movie recommendations for a specified set of users  
users = ratings.select(als.getUserCol()).distinct().limit(3)  
userSubsetRecs = model.recommendForUserSubset(users, 10)  
# Evalute top 10 user recommendations for a specified set of movies  
movies = ratings.select(als.getItemCol()).distinct().limit(3)  
movieSubSetRecs = model.recommendForItemSubset(movies, 10)  
